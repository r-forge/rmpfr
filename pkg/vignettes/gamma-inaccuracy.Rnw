\documentclass[article,nojss]{jss}%-- the LONGER version
%% NOTA BENE: More definitions --> further down
%%%%%%%%%%%%
%
\author{Martin M\"achler \\ ETH Zurich%
\\ April, 2022 {\tiny (\LaTeX'ed \today)}%---- for now
}
\title{Accurately Computing the Gamma Function $\Gamma(x)$}
%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Martin M\"achler} %% comma-separated
\Plaintitle{Accurately Computing the Gamma Function}
%\VignetteIndexEntry{Accurately Computing Gamma}
%\VignetteDepends{Rmpfr}
%\VignetteDepends{gmp}
%\VignetteDepends{sfsmisc}
%\SweaveUTF8
% ^^^^^^^^^^ (for now, have UTF-8 in comment only!)
\SweaveOpts{engine=R,strip.white=true, width=8.5, height=6}
\SweaveOpts{pdf=FALSE, eps=FALSE, grdevice = pdfaCrop}
%      defined in R  " <preliminaries>":     ^^^^^^^^

\Abstract{
  Interestingly enough it lasted more than 25 years before I (re-)detected
  that \R's not perfectly accurate gamma function \code{gamma(x)}
  $ = \Gamma(x)$ can quite easily be remedied --- amazingly by
  \emph{simplifying} the underlying C source code:
  Higher accuracy than previously is achieved by using $\Gamma()$'s  simple functional
  equation, \[
    \Gamma(x+1) = x \cdot \Gamma(x),
  \]
  recursively, for the full range of \code{x} instead of just when
  $\abs{x}$ is smallish.
  \par\noindent % \\[1.5ex]
  Interestingly, the improvement did not help the computation of
  \code{factorial(x) := gamma(x + 1)} in some situations for which I needed
  some time before understanding why.
}
\Keywords{Accuracy, Cancellation Error, Gamma, Factorial, MPFR, Rmpfr}

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{13}
%% \Issue{9}
%% \Month{September}
%% \Year{2004}
%% \Submitdate{2004-09-29}
%% \Acceptdate{2004-09-29}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
	Martin M\"achler\\
	Seminar f\"ur Statistik, HG G~16\\
	ETH Zurich\\
	8092 Zurich, Switzerland\\
	E-mail: \email{maechler@stat.math.ethz.ch}\\
	URL: \url{https://stat.ethz.ch/~maechler}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/1/31336-5053
%% Fax: +43/1/31336-734

%% for those who use Sweave please include the following line (with % symbols):
%% MM: this is "substituted" by  jss.cls:
%% need no \usepackage{Sweave.sty}

\usepackage[american]{babel}%for American English
\usepackage{amsmath}%sophisticated mathematical formulas with amstex (includes \text{})
\usepackage{mathtools}%fix amsmath deficiencies
\usepackage{amssymb}%sophisticated mathematical symbols with amstex (includes \mathbb{})
% \usepackage{amsthm}%theorem environments
\usepackage{bm}%for bold math symbols: \bm (= bold math)
\usepackage{enumitem}%for automatic numbering of new enumerate environments

% This is already in jss above -- but withOUT the  fontsize=\small part !!
\DefineVerbatimEnvironment{Sinput}{Verbatim}{fontsize=\small,fontshape=sl}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{fontsize=\small}
\DefineVerbatimEnvironment{Scode}{Verbatim}{fontsize=\small,fontshape=sl}
%%~-~-~-~ Make space between Sinput and Soutput smaller: ~-~-~-~~-~-~-~~-~-~-~~-~-~-~~-~-~-~
%%--- Best advice, now from :
% http://tex.stackexchange.com/questions/19359/reduce-space-between-sinput-and-soutput
\newlength{\FVtopsep}
\newlength{\FVpartopsep}
\newlength{\FVparskip}% <- added as "no. 3" by MMa (after reading fancyvrb doc)
\makeatletter
\FV@AddToHook{\FV@ListParameterHook}{\topsep=\FVtopsep\partopsep=\FVpartopsep\parskip=\FVparskip}
\makeatother
% Control the spacing around the Sinput and Soutput environments by using the lengths
%
%     \FVtopsep
%     \FVpartopsep
%     \FVparskip
%
% Both *topsep  act quite similar most of the time, more details
% can be found in the fancyvrb documentation on page 46. (MM: ==> I add FVparskip)
%To kill all extra spacing between the environments, use {0pt} in all these
%MM: When all three(!) are {0pt}, there's a large gap *after* Schunk (nothing in %between)
%--  and that (end gap) get's smaller when I set all to {1pt} -- logic??
%___TODO/FIXME: Set of experiments (with smaller Sweave file)___
\setlength{\FVtopsep}{1pt}
\setlength{\FVpartopsep}{1pt}
\setlength{\FVparskip}{\parskip}% default: \parskip
%%~-~-~-~ End {Sweave space handling} ~-~-~-~~-~-~-~~-~-~-~~-~-~-~~-~-~-~~-~-~~-~-~-~~-~-~
%%
\setkeys{Gin}{width=\textwidth}% Sweave.sty has {width=0.8\textwidth}

\newcommand*{\R}{\proglang{R}}%{\textsf{R}}
\newcommand*{\CRANpkg}[1]{\href{http://CRAN.R-project.org/package=#1}{\pkg{#1}}}
\newcommand*{\file}[1]{\code{#1}}

\newcommand*{\eps}{\varepsilon}
%- \abs{ab}  -->  | ab |   ``absolut Betrag''
\newcommand{\abs}[1]{\left| #1 \right|}
\DeclareMathOperator{\sign}{sign}
%% journal specific aliases
\newcommand*{\setcapwidth}[1]{}

\newcommand*{\floorF}[1]{\left\lfloor{#1}\right\rfloor}
\newcommand*{\fx}{\floorF{x}}
%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
%% include your article here, just as usual
%% Note that you should use the \pkg{}, \proglang{} and \code{} commands.
% \section[About Java]{About \proglang{Java}}
%% Note: If there is markup in \(sub)section, then it has to be escape as above.
%%
%% Note: These are explained in '?RweaveLatex' :
<<preliminaries, echo=FALSE, results=hide>>=
## Our custom graphics device:
pdfaCrop <- function(name, width, height, ...) {
    fn <- paste(name, "pdf", sep = ".")
    if(FALSE)## debug
        cat("pdfaCrop: fn = ",fn,"; call:\n\t",deparse(match.call()),"\n")
    grDevices::pdf(fn, width = width, height = height, onefile=FALSE)# ...)
    assign(".pdfaCrop.name", fn, envir = globalenv())
}
## This is used automagically :
pdfaCrop.off <- function() {
    dev.off()# for the pdf
    f <- get(".pdfaCrop.name", envir = globalenv())
    ## and now crop that file:
    pdfcrop <- "pdfcrop" # relying on PATH - fix if needed
    pdftex  <- "pdftex"  # relying on PATH - fix if needed
    system(paste(pdfcrop, "--pdftexcmd", pdftex, f, f, "1>/dev/null 2>&1"),
           intern=FALSE)
}
op.orig <-
options(width = 75,
	## SweaveHooks= list(fig=function() par(mar=c(5.1, 4.1, 1.1, 2.1))),
	digits = 5,
	useFancyQuotes = "TeX",
	## for JSS, but otherwise MM does not like it:
	## prompt="R> ",
	continue="  ")# 2 (or 3) blanks: use same length as 'prompt'

if((p <- "package:fortunes") %in% search())
    try(detach(p, unload=TRUE, char=TRUE))
Sys.setenv(LANGUAGE = "en")
if(.Platform$OS.type != "windows")
  Sys.setlocale("LC_MESSAGES","C")
library("sfsmisc")# e.g., for eaxis()
library("Rmpfr")
@
%\section[Introduction]{Introduction \small~\footnote{\mythanks}}
\section[Introduction: exp(x) less accurate]{
  Introduction: exp(x) may be less accurate than x}

Something many people have either not been aware at all or
(as myself) forgotten:  Whereas typical arithmetic operations keep the
internal accuracy, hopefully only losing a bit or two when the operation is
implemented well, this is not the case for exponentiation when the exponent
is not close to $[-1,1]$:

If we have an $x$ with relative inaccuracy $\eps$, or to make it shorter,
directly assume we have $\tilde x := x(1+\eps)$ instead of $x$,
instead of $f(x) = \exp(x) = e^x$, we'd compute --- if $e^x$ would be perfectly exact ---
\begin{align}
  \label{eq:exp-eps}
  f(\tilde x) = \exp(x(1+\eps)) = e^{x(1+\eps)} = e^x e^{x\eps} = f(x) \cdot e^{x \eps},
\end{align}
where the relative error $\tilde\eps$ is defined (implicitly) via
\(
  f(\tilde x) = f(x) \cdot (1 + \tilde\eps),
\)
i.e., we have
\begin{align}
  \label{eq:exp-err}
 1 + \tilde \eps = e^{x \eps}     &=         1 +     x\eps + (x\eps)^2/2! + O\bigl((x\eps)^3\bigr),
                    \quad \textrm{and hence,}\nonumber\\
     \tilde \eps = e^{x \eps} - 1 &=\phantom{1 + \ } x\eps + (x\eps)^2/2! + O\bigl((x\eps)^3\bigr),
\end{align}
and hence in good cases, when $\abs{x\eps} \ll 1$, we have
$\abs{\tilde \eps} = e^{x \eps} - 1 \approx \abs{x\eps}$, i.e., the
relative error is blown up by $\abs{x}$.
In a bad case, $\abs{x\eps} \approx 1$ the blow up would be horrendous,
but that will not happen with double precision:

Given double precision arithmetic, the exponents $x$ of \code{exp(x)}
which do not overflow (to \code{Inf}) nor underflow to 0 are not too large, specifically,
<<exp-boundaries>>=
rbind(
  regular = log(c(min = .Machine$double.xmin,      max = .Machine$double.xmax)),
  denormal= log(c(min = .Machine$double.xmin/2^52, max = .Machine$double.xmax)) )
@
so exponents are still in the order of 1000, i.e., such that exponentiation
may lose up to 3 decimals.

Now, losing 3 out of almost 16 digits is not catastrophical,
and in situations such as graphics or analysis of noisy data often irrelevant.  But
we want to be able to use \R\ not just for data analysis but also as
scientific calculator with typically
``high'' accuracy. % often better than *any* other applied math engine ..

Our way to measure accuracy of \R's computations is by using our package
\CRANpkg{Rmpfr}'s ability to do many computations with arbitrary high precision.
The package \CRANpkg{Rmpfr} is an interface from \R\ to the MPFR C library.
According to Wikipedia:
\begin{quote}
  The GNU Multiple Precision Floating-Point Reliable Library (GNU MPFR) is a
  GNU portable C library for arbitrary-precision binary floating-point
  computation with correct rounding, based on GNU Multi-Precision Library.
\end{quote}

Also, this is the principal reason why \code{gamma(x)} in \R, has been
losing up to about 3 digits in accuracy till \R~4.2.0 at least, when $x >
10$, as it basically has used \code{gamma(x) := exp(lgamma(x))} for these $x$
values, as the \code{exp()}onentiation may lose accuracy there.


\section[Computation of Gamma]{Computation of Gamma, \(\Gamma(x)\)}

We measure and visualize the accuracy of \R's \code{gamma(x)}
and in the next section also of \R's \code{gamma(x+1)} which because of $x! := \Gamma(x+1)$ (also for
% non-integer $x$) has even been defined as
<<factorial-def, eval=FALSE>>=
  factorial := function(x) gamma(x + 1)
@
in \R.
In both cases, we compute the function in base \R\ with double precision
vector argument \code{x} and also compute high-accuracy function values
using \code{mpfr(x, 256)} instead of \code{x}, where the \code{Rmpfr}
package \code{mpfr()} creates a 256-bit mantissa version of \code{x} and
when passed to \code{gamma()} calls the Rmpfr version of these.%
\footnote{Note that \code{gamma()} (and many similar special math functions) is not
  explicitly exported from \CRANpkg{Rmpfr} but used as a \code{method} of the
  \code{Math()} S4 group generic function.  This is one reason for wanting
  \code{Rmpfr} attached to the \code{search()} path.}

In addition, we make use of our package \CRANpkg{sfsmisc}'s
\code{relErrV()} function which basically computes the relative error
(\textsc{v}ectorized) of an approximate $\hat\theta$ wrt a true $\theta$,
i.e.,
$(\hat\theta - \theta)/\theta =  \hat\theta / \theta - 1$.  The
\code{relErrV()} function is careful to switch to absolute error
$\hat\theta - \theta$ in case $\theta \approx 0$, and to
return $0$ when both values are the same, e.g., for \code{0}, \code{NaN}, or \code{Inf},
and similar.

The \code{p.gammEr()} and \code{p.factEr()} functions can compute and
visualize the relative errors for \code{gamma()} and \code{factorial()} in
one call, however also allow what we do here, i.e., to separate most of the
computation from the visualization (plotting)
and \emph{pass} both vectors of function values, the double precision base \R\ and the package
\pkg{Rmpfr} high-accuracy ones, to the plotting function as arguments:

%%   source("gamma-inaccuracy_src/plot-gammaErr-def.R")
<<plot-gammaErr-def, echo=FALSE>>=
\SweaveInput{gamma-inaccuracy_src/plot-gammaErr-def.R}
@
%%   source("gamma-inaccuracy_src/plot-factErr-def.R")
<<plot-factErr-def, echo=FALSE>>=
\SweaveInput{gamma-inaccuracy_src/plot-factErr-def.R}
@
<<p.gammaEr-str>>=
str(removeSource(p.gammEr))
## and p.factEr() is defined analogously
@

We do \emph{not} use binary-nice numbers such as I had originally,
<<nice-binary, eval=FALSE>>=
xF <- unique(sort(c(seq(-180, 180, by=1/16), outer(-180:180, c(-1/32, 1/64), "+"))))
@
Rather, we want their non-integer part, i.e., $x - \fx$, called \code{u01}
below, to be a mixture of nice (in binary!) ($\frac{k}{16}$) and nicely
\emph{looking} in decimal, but ``not binary-nice'' floating point numbers
resulting from $\frac{m}{80}$ when $m$ is not divisible by 5 (which would need
an infinite binary fraction representation):
<<xF-values>>=
\SweaveInput{gamma-inaccuracy_src/xF-xG.R}
@
%  source("gamma-inaccuracy_src/xF-xG.R")

% These are already sorted, and have ``delta x'' values $x_{i+1} - x_i$
% either $1/80$ or $2/80 = 1/40$:
% <<xF-2>>=
% stopifnot(all.equal((1:2)/80, range(diff(xF))),
%           all.equal((1:2)/80, range(diff(xG))))
% length(xF)
% @
% % = 16575

We compute base \R's gamma, and then also \pkg{Rmpfr}'s
\code{gamma} method, using 256-bit precision:
<<gamma-comp>>=
gammxG <- gamma(xG)
system.time(# 256-bit (~= 256*log10(2) ~= 77 digits) internal accuracy to be "safe")
    gammMxG <- gamma(mpfr(xG, 256))
) # 0.3 sec
@

Is 256 bits enough?  Use a twice as accurate computation with 512 bits to
check the ``error'' of the the 256-bit computations:
<<gamma-mpfr-prec>>=
gammMM <- gamma(mpfr(xG, 512))
rEM <- asNumeric(roundMpfr(relErrV(gammMM, gammMxG), 30))[xG %% 1 != 0]
summary(rEM)
-log2(8.5e-78) # 256.02
@
% summary(rEM) :
%      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.
% -8.50e-78 -2.99e-78  0.00e+00 -2.6e-81  3.00e-78  8.36e-78

So, the largest relative errors being $\approx 2^{-256}$, indeed, the
256-bit \code{Rmpfr}--version is accurate to (about) the last bit.

<<read-oldR-gamma>>=
## Code in ./gamma-inaccuracy_src/gamma-inaccuracy-4old.R
Rver <- "4.1.3" # or also "4.2.0" ..
gamRfile <- paste0("gamma-inaccuracy_src/gamma_R-", Rver, ".rds")
oldG <- readRDS(gamRfile)
stopifnot(identical(xF, oldG[,"xF"])) # the 'x' values are the same
@

In Fig.~\ref{fig:relE-gamm-old} we look at the current \R\ version's accuracy of
\code{gamma(x)}, for the whole range of $x$ for which \code{gamma(x)} does
not underflow to zero nor overflow to \code{+Inf}.
\enlargethispage{3ex}
\begin{figure}[hbt]
  \centering
<<plot-gammErr-oldR-neg-pos, fig=TRUE, height=5.25, echo=FALSE>>=
pgEpmO <- p.gammEr(oldG[,"xG"], oldG[,"gamm.x"], gammMxG,
                   ch.Rversion = attr(oldG, "R.version"),
                   type="l", ylim2 = c(1e-17, 2e-13), doFirst = FALSE)
@
  \caption[|relative errors| of R's gamma()]{Absolute values of relative error of \R's
    \code{gamma(x)} (compared to its 256-bit \code{Rmpfr}-package version).
    Note that values for $x \in \{1,\dots,23\}$ are exact, i.e, have
    $\abs{rE(x)} = 0$, because for positive integer $x = n \le 50 $,
    \code{gamma(n) == factorial(n-1)} has been implemented by computing the
    product $(n-1)! = 1 \cdot 2 \cdot (n-1)$,
    since May 16, 2003, svn rev 24344 by maechler.}
  \label{fig:relE-gamm-old}
\end{figure}

Also, we notice that there is a ``break'' in accuracy where $\Gamma(x)$ is
much better approximated by \R's \code{gamma(x)} for $x \in [-10, 10]$ than
when it is outside, i.e., $\abs{x} > 10$.

This is because the ``old'' traditional \R\ algorithm for \code{gamma()} is basically just using
\begin{enumerate}
\item a fully accurate (double precision) Chebyshev polynomial
  approximation for $\Gamma(x), \ x \in [1,2]$ (where $\Gamma$ looks vaguely
  like a quadratic function with minimum at
  $(x_0, \Gamma(x_0)) = (1.461632144968\dots, 0.88560319441\dots)$, see
  \url{https://en.wikipedia.org/wiki/Gamma_function#Minima}
  %% zmin ≈1.46163214496836234126 .. where it attains the value Γ(zmin) ≈ 0.88560319441088870027 .
  and values
  $\Gamma(1) = \Gamma(2) = 1$ at the interval boundaries).
  \begin{center}\par\vspace*{-1ex}
    \begin{minipage}{.5\linewidth}
<<plot-gamma-in-1_2, fig=TRUE, height=2.6, echo=FALSE>>=
      par(mgp = c(1.5, .6, 0), mar = 0.1 + c(3,3:1))
      curve(gamma, 1,2, n=501, col=2, lwd=2, asp=1, ylab="", las=1)
      title(quote(Gamma(x) ~ "for"~ x %in% group("[",list(1,2),"]") ~~ "via 22-d Chebyshev polynomial"))
      abline(h=1, v=1:2, lty=2, col="gray")
      x0 <- 1.461632145; points(x0, gamma(x0), col=4, pch=3, cex=3, type="h")
      axis(1, at=x0, col=4, col.axis=4, cex.axis=2/3, padj=-2)
@
    \end{minipage}
  \end{center}
\item for $\abs{x} \le 10$ uses the
  $Gamma()$ recursion formula $\Gamma(x+1) = x\Gamma(x)$, repeatedly, see
  also (\ref{eq:Gamma-recursion}).
\item for $\abs{x} > 10$ computes $\Gamma(x) = \exp(\mathtt{lgamma(x)})$
  via the \code{lgamma()} function which computes $\log\Gamma(x)$ via a
  (generalized) asymptotic Stirling formula.
\end{enumerate}


Further, note that \code{factorial(171)} overflows to \code{+Inf} as indeed,
<<fact171>>=
f171 <- factorial(mpfr(171, precBits=128))
noquote(format(f171))
asNumeric(f171 / .Machine$double.xmax)
@
i.e., $171!$ ``must'' overflow in double precision.

Now, we zoom into the (more ``common'') region
$x \in [1, 50]$, and then extend the range to
all positive $x$ (for which \code{gamma()} is still finite):

<<plot-gammErr-1, fig=TRUE>>=
str(i1 <- which(1 <= xG & xG <= 50)); stopifnot(!anyNA(i1))
pgE1 <- p.gammEr(xG[i1], gammxG[i1], gammMxG[i1], ylim2=c(1e-18, 1e-15))
@



%% ================ "Part 2":
\section[Computation of Gamma(x+1) = Factorial]{
  Computation of  Factorial \(\Gamma(x+1) = x!\)}


%%------------------------------------------------------------------
The same with \code{factorial()} instead of \code{gamma()}:
%%------------------------------------------------------------------

We compute base \R's factorial, and then also \pkg{Rmpfr}'s
\code{factorial} method, using 256-bit precision:
<<factorial-def, eval=FALSE>>=
  factorial :=  function(x)  gamma(x + 1)
<<factorial-comp>>=
facxF <- factorial(xF)
system.time(# 256-bit (~= 256*log10(2) ~= 77 digits) internal accuracy to be "safe")
    facMxF <- factorial(mpfr(xF, 256))
) # 0.3 sec; then (LDOUBLE): 0.81 sec
@

To compare the old (``current'' at time of writing) and potential new
algorithms visually, we get their values from a saved version of what above would be
\code{ cbind(x = xG, fact.x = facxF, gamm.x = gammxG) }  :
%\code{ cbind(x = xF, fact.x = facxF) }  :


Then, (Fig.~\ref{fig:relE-fac-old}) we look at the current \R\ version's accuracy of
\code{factorial(x)} or equivalently \code{gamma(x+1)}, for the whole range
of $x$ for which \code{factorial(x)} is positive and finite.
\enlargethispage{3ex}
\begin{figure}[hbt]
  \centering
<<plot-factErr-oldR-neg-pos, fig=TRUE, height=5.25, echo=FALSE>>=
pfEpmO <- p.factEr(oldG[,"xF"], oldG[,"fact.x"], facMxF,
                   ch.Rversion = attr(oldG, "R.version"),
                   type="l", ylim2 = c(1e-17, 2e-13), doFirst = FALSE)
@
  \caption[|relative errors| of R's factorial()]{Absolute values of relative error of \R's
    \code{factorial(x)} (compared the 256-bit \code{mpfr} version).
    Note that $x!$ values for $x \in \{0,1,\dots,22\}$ are exact, as
    explained in Fig.~\ref{fig:relE-gamm-old}'s caption above.}
  \label{fig:relE-fac-old}
\end{figure}

We observe that it seems the simple product for integer $x$ should be used
for all $n \in \{0,1, \dots, 170\}$, instead of just up to 50.

For \code{factorial(x)}$ = x! = \Gamma(x+1)$, using $[0, 49]$ analogously,
<<plot-factErr-1, fig=TRUE>>=
str(i1 <- which(0 <= xF & xF <= 49)); stopifnot(!anyNA(i1))
pfE1 <- p.factEr(xF[i1], facxF[i1], facMxF[i1])
@
This is really surprisingly different from the figure above! %% TODO: Fig.~\ref{}
Note that the visual outliers can be easily be separated, and clustered
very distinctively into 5 groups:
<<cluster-iLarge, fig=TRUE, height=5>>=
iLarge <- which(abs(pfE1[,"relErr"]) > 2e-15 |
               (abs(pfE1[,"relErr"]) > 4e-16 & pfE1[,"x"] < 10))
 xLrg <- xF[i1][iLarge]
rELrg <-  pfE1 [iLarge, "relErr"]
require(cluster)
clLrg <- pam(xLrg, 4)
str(split(xLrg, clLrg$clustering), digits=6)

plot(abs(rELrg) ~ xLrg, type="o", log="xy", axes=FALSE, ylim=c(2e-17, 2e-14))
xI <- outer(-1:0, 2^(2:5), `+`); cg <- adjustcolor("gray20", 1/3); abline(v = xI, lty=2, col=cg)
eaxis(1, sub10=2, at=xI);  eaxis(2)
lines(abs(pfE1[,"relErr"]) ~ xF[i1], col=cg, lwd=1/2)
abline(h = 2^(0:2)*2^-53, col="orange", lty=3)
@

which shows for \emph{some} (actually exactly $\frac 1 3$, i.e. one third)
of the $x$ values in the intervals $(3,4)$, $(7,8)$, $(15,16)$, and $(31,32)$,
there are ``outliers'' with quite substantial accuracy loss.

For a typical one in interval $(3,4)$, if I do the multiplications manually in \R,
everything remains amazingly accurate:
<<relE-0.98>>=
Mfac3.98 <- factorial(mpfr(3.98, 128)) ## all these three are the same
c(asNumeric((factorial(0.98)*1.98*2.98*3.98)/Mfac3.98 - 1)
, asNumeric((factorial(0.98)*(1+.98)*(2+.98)*(3+.98))/Mfac3.98 - 1)
, asNumeric((gamma(1.98)*(1+.98)*(1+1+.98)*(1+1+1+.98))/Mfac3.98 - 1) )
@
where the error is only $2.43 \cdot 10^{-17}$, almost 10 times smaller than
the computer epsilon $2^{-52}$,
and about 80 times smaller than the 7.87..e-16 we got from \R's C-base
evaluation \code{factorial(3.98)}.
However, if I get close to what \R\ does, I can now get
<<relE-0.98_RinC>>=
c(asNumeric((gamma(4.98-3) * (4.98-1)*(4.98-2)*(4.98-3))/Mfac3.98 - 1) ,
  asNumeric((gamma(4.98-3) * (4.98-3)*(4.98-2)*(4.98-1))/Mfac3.98 - 1) )
@
for which I see larger errors 6.345..e-16 and 7.871..e-16, respectively.

Similar observation if we extend to the whole (finite $\Gamma()$) positive
axis: $\Gamma(x)$ is perfectly accurate (new algorithm), whereas $x!$ has ``outliers'':

<<plot-gammErr-full, fig=TRUE>>=
str(i2 <-  which(1 <= xG & xG <= 173)); stopifnot(!anyNA(i2))
pgE2 <- p.gammEr(xG[i2], gammxG[i2], gammMxG[i2], ylim2=c(1e-18, 1e-15))
@

<<plot-factErr-full, fig=TRUE>>=
str(i2 <-  which(0 <= xF & xF <= 172)); stopifnot(!anyNA(i2))
pfE2 <- p.factEr(xF[i2], facxF[i2], facMxF[i2], ylim2=c(1e-18, 1e-15))
@

% The ``old'' \R\ algorithm for \code{gamma()} is basically just using
% \begin{enumerate}
% \item a fully accurate (double precision) Chebyshev polynomial
%   approximation for $\Gamma(x), \ x \in [1,2]$ (where $\Gamma$ looks vaguely
%   like a quadratic function with minimum at
%   $(x_0, \Gamma(x_0)) = (1.461632144968\dots, 0.88560319441\dots)$, see
%   \url{https://en.wikipedia.org/wiki/Gamma_function#Minima}
%   %% zmin ≈ 1.46163214496836234126 .. where it attains the value Γ(zmin) ≈ 0.88560319441088870027 .
%   and values
%   $\Gamma(1) = \Gamma(2) = 1$ at the interval boundaries)
% \item for $\abs{x} \le 10$ uses the
%   $Gamma()$ recursion formula $\Gamma(x+1) = x\Gamma(x)$, repeatedly, see
%   also (\ref{eq:Gamma-recursion}).
% \item for $\abs{x} > 10$ computes $\Gamma(x) = \exp(\mathtt{lgamma(x)})$
%   via the \code{lgamma()} function which computes $\log\Gamma(x)$ via a
%   (generalized) asymptotic Stirling formula.
% \end{enumerate}

We find the accuracy of this by visualizing the relative error of \R's
\code{gamma(x)} wrt to the 256-bit accurate mpfr-values.

%% ... FIXME ...

For that, we the values from a saved version of what above would be
\code{ cbind(x = xF, fact.x = facxF) }  :

<<oldR-factEr>>=
i.10 <- abs(xF+1) <= 10 # <==> -11 <= xF <= 9
all.equal(facxF[i.10], oldG[i.10,"fact.x"])
@
which \emph{differ} as we now use a different  \code{ value *= (..) ; } scheme in the
multiplication \code{for}-loop.
% i.e., indeed, \code{gamma(x)} is unchanged for $x \in [-10, 10]$, and hence,
% \code{factorial(x)} is unchanged for $x \in [-11,9]$.

Now we choose larger $y$-axis limits (\code{ylim = *}) to compare both the
old and the new algorithm behavior:

<<plot-factErr-oldR-full-ylim, fig=TRUE>>=
p.factEr(oldG[i2,"xF"], oldG[i2,"fact.x"], facMxF[i2],
         ch.Rversion = attr(oldG, "R.version"), type="o",
         ylim1 = c(-1,1)*8e-14, ylim2 = c(.5e-17, 2e-13))
<<new-device, echo=FALSE>>=
if(dev.interactive()) dev.new()
<<plot-factErr-newR-full-ylim, fig=TRUE, echo=FALSE>>=
p.factEr(xF[i2], facxF[i2], facMxF[i2], type="o",
         ylim1 = c(-1,1)*8e-14, ylim2 = c(.5e-17, 2e-13))
@

and then using positive \emph{and} negative arguments $x$ for the new algorithm,
which is perfect for the $\Gamma(x) :=$\code{gamma(x)},

<<plot-gammErr-neg-pos, fig=TRUE, echo=FALSE>>=
pgEpm <- p.gammEr(xG, gammxG, gammMxG, type="l", ylim2= c(1e-17, 2e-13))
@

but quite different, with the ``outliers'' for \code{factorial(x)}

<<plot-factErr-neg-pos, fig=TRUE, echo=FALSE>>=
pfEpm <- p.factEr(xF, facxF, facMxF, type="l", ylim2= c(1e-17, 2e-13))
@

where for the ``old'' \R\ version, we've seen the \emph{absolute} values of
the relative errors, i.e., the 2nd plot, already above in Fig.~\ref{fig:relE-fac-old}.

Now compare the relative errors of the traditional ``old'' \code{gamma(.)}
and the new one, using the simple recursion derived from the identity
$\Gamma(x+1) = x\Gamma(x)$,
i.e.,
\begin{align} \label{eq:Gamma-recursion}
  \Gamma(x+1) & = x(x-1)\cdots(x-\fx+k+1)\Gamma(x-\fx+k) \mathrm{\ for\ } k=0,1,\dots,\fx
  \\ & \nonumber
  % using \mathtt{} : \code{} involves ttfamily in way of --> error
  \mathrm{\ and\ where\ } \fx \mathrm{\ is\ \R's\ } \mathtt{floor(x)}.
\end{align}

Both old and new algorithm together, for  the $\Gamma(x) :=$\code{gamma(x)},

<<plot-gammErr-both, fig=TRUE, echo=FALSE>>=
matpl2 <- function(x, y, main, ylim = c(2e-17, 2e-13),
                   col = adjustcolor(2:1, 2/3), vcol = "sky blue",
                   vert = c(-10, 10)) {
    op <- par(mgp=c(2, .4, 0)); on.exit(par(op))
    matplot(x, y, type="o", cex=1/2, pch=2:1, lty=1,
            xlab=quote(x), ylab=quote(abs(rE)), main=main,
            ylim=ylim, col=col, log="y", yaxt='n')
    sfsmisc::eaxis(2, cex.axis=.8)
    legend("top", c("new R devel", "old R 4.1.3"), col=col, lty=1, pch=2:1, bty='n')
    abline(v = vert, lty=3, col=vcol)
    for(s in c(1,3)) axis(s, at = vert, col=vcol, col.axis=vcol)
}

relE2 <- cbind(n.relE = pgEpm[,"relErr"], o.relE = pgEpmO[,"relErr"])
matpl2(pgEpm[,"x"], relE2, main = "|relative error{ gamma(x) }|")
@

<<plot-factErr-both, fig=TRUE, echo=FALSE>>=
relE2 <- cbind(n.relE = pfEpm[,"relErr"], o.relE = pfEpmO[,"relErr"])
matpl2(pfEpm[,"x"], relE2, main = "|relative error{ x! }|",
       vert = c(-11,9))
@

\subsection{Extending the domain, i.e. range(x) with finite gamma()}
In addition to always use the new algorithm, i.e., use the
recursion~(\ref{eq:Gamma-recursion}),
$ \Gamma(x+1) = x(x-1)\cdots(x-\fx+k+1)\Gamma(x-\fx+k)$ everywhere,
we can also extended the range of $x$ which gives finite
$\Gamma(x)=$\code{gamma(x)} in \R:

Here, we want to determine the smallest and largest possible \code{x} such
that \code{gamma(x)} is finite, \emph{more}* accurately (and allowing
denormalized numbers) than \R's (internal) \code{gammalims()}, which had
been hard coded to the interval  $(-170.567...., 171.614....)$.

The upper bound \code{'xmax'} :
\\
<<compute-xmax>>=
str(ur <- uniroot(function(x) asNumeric(gamma(mpfr(x, 256))/.Machine$double.xmax - 1),
                  c(170,180), tol=1e-14), digits=12)
xmax <- ur$root
dput(xmax, , "digits") # 171.62437695630271
asNumeric(gamma(mpfr(171.62437695630271, 256))/.Machine$double.xmax - 1)
## -4.7749e-14  < 0  <==>  gamma(.) < Machine..xmax
@

The lower bound \code{'xmin'} --- this considerably more delicate, as we
have odd poles here at each negative integer, $\Gamma(x)$ ``jumping'' from
$+\infty$ to $-\infty$ (or the other way round.
In the end we will \emph{not} use the value found here but rather even a
slightly smaller one, $x_{\mathrm{min}\Gamma} = -182$ and use a version of
$\log\Gamma(x)$, i.e., code from \R's \code{lgamma()} for values of $x$
which lead to ``sub normal'' $gamma(x)$ values, i.e., \code{abs(gamma(x)) <
.Machine\$double.xmin} ($ = 2^{-1022}$ for the IEEE double precision standard).
\\
<<compute-xmin>>=
str(uL <- uniroot(function(x) asNumeric(abs(gamma(mpfr(x, 256))/2^-1073.9999) - 1),
                  c(-180.1, -170.1), tol=1e-14), digits=12)
dput(uL$root, , "digits") # -177.56341258681965

asNumeric(gamma(mpfr(-177.56341258681965, 256))/2^-1073.9999 - 1)
## 1.71551e-14 > 0  <==> gamma(.) > Machine..denormalized_xmin  .. good
@

Consequently, the proposal is to have in \R's source \file{<R>/src/nmath/gamma.c},
\begin{verbatim}
// now allowing denormalized result
# define xmin -177.56341258681965 // was -170.5674972726612
# define xmax  171.62437695630271 // was  171.61447887182298
\end{verbatim}

However, on April 29, 2022, analyzing more on these experiments, now in
accompanying file
\file{gamma-inaccuracy\_src/gamma-subnormal.R},
%%    gamma-inaccuracy_src/gamma-subnormal.R
we've found two properties

\begin{enumerate}
\item In the case of ``no \code{"long.double"} '',  and in the subnormal
  range, I've found that  \code{exp(lgamma(x))} \emph{with correct sign}
  is clearly superior to the recursive formula !!
\item In the (typical) \code{"long.double"} case, we've further seen that
  we should \emph{not} ``explicitly'' underflow to zero, i.e., via
  \code{ if(x < xmin) return(0) } too quickly (say for \code{xmin = -177.5635}),
  but rather use our code down to about \code{xmin := -178.1} .
\end{enumerate}

TODO: show more here

And indeed, we can see
<<gamma-xtreme>>=
if(capabilities("long.double")) withAutoprint({
 gamma(-177.56341258681968 * (1 - c(0, 2e-16))) #  0  4.4907e-324
 gamma(-177.56341258681962) # 4.4907e-324
 gamma(-177.56341258681962) == 2^-1074
}) else withAutoprint({ ## no long double
 gamma(-177.44546702405586 * (1 - c(0, 2e-16))) #  0  1.976263e-323
 gamma(-177.44546702405583) # 1.976263e-323
 gamma(-177.44546702405583) == 2^-1072
})

## The upper boundary is correctly giving  (1.7977e308, Inf)  {with and withOUT long double}:
gamma( 171.62437695630271 * (1 + c(0, 3e-16)))
@

% ##=======>  gamma(x) itself suffers from the fact that  exp(y) has a *large* relative error,
% ##          -------- when  |y| ~ 100 or so, more specifically, the
% ## relative error of   exp(y) =  |y| * {rel.err(y)} , since
% ##   exp(((1+ eps)*y) = exp(y) * exp(eps*y) >=  exp(y) (1 + eps*y)  and indeed,
% ## the inaccuracy of y (i.e. eps)  is blown up by a factor |y|  which is not small here!

\subsection*{Session Information}
\nopagebreak
<<final-info>>=
capabilities("long.double")
<<sessionInfo, results=tex>>=
toLatex(sessionInfo(), locale=FALSE)
<<finalizing, echo=FALSE>>=
options(op.orig)
@
%\clearpage

% \bibliography{gamma-inacc}

\end{document}
